{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 84.0.4147\n",
      "[WDM] - Get LATEST driver version for 84.0.4147\n",
      "[WDM] - Driver [/Users/abby/.wdm/drivers/chromedriver/mac64/84.0.4147.30/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "# browser = Browser('chrome', **executable_path)\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "# browser = Browser('chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.walmart.com'\n",
    "search_url = '/search/?query=room%20air%20purifier'\n",
    "browser.visit(base_url + search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = soup.find_all('div', class_='search-result-gridview-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Image</th>\n",
       "      <th>AverageStars</th>\n",
       "      <th>NumberofReviews</th>\n",
       "      <th>ReviewsURL</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High-Efficiency HEPA-Type Desktop Air Purifier...</td>\n",
       "      <td>https://www.walmart.com/ip/High-Efficiency-HEP...</td>\n",
       "      <td>https://i5.walmartimages.com/asr/5ba9740e-a3f1...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>136</td>\n",
       "      <td>https://www.walmart.com/ip/High-Efficiency-HEP...</td>\n",
       "      <td>$52.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Filtrete F2 Bacteria &amp; Virus True HEPA Room Ai...</td>\n",
       "      <td>https://www.walmart.com/ip/Filtrete-F2-Bacteri...</td>\n",
       "      <td>https://i5.walmartimages.com/asr/dea94bac-be28...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>55</td>\n",
       "      <td>https://www.walmart.com/ip/Filtrete-F2-Bacteri...</td>\n",
       "      <td>$17.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Filtrete by 3M Room Air Purifier, Console, 110...</td>\n",
       "      <td>https://www.walmart.com/ip/Filtrete-by-3M-Room...</td>\n",
       "      <td>https://i5.walmartimages.com/asr/eae28c2f-5dbe...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>195</td>\n",
       "      <td>https://www.walmart.com/ip/Filtrete-by-3M-Room...</td>\n",
       "      <td>$49.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Air Purifier for Home Large Room with HEPA Fil...</td>\n",
       "      <td>https://www.walmart.com/ip/Air-Purifier-Home-L...</td>\n",
       "      <td>https://i5.walmartimages.com/asr/ea3ecf29-543f...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.walmart.com/ip/Air-Purifier-Home-L...</td>\n",
       "      <td>$88.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airfree T800 Filterless Virus Destroying Air P...</td>\n",
       "      <td>https://www.walmart.com/ip/Airfree-T800-Filter...</td>\n",
       "      <td>https://i5.walmartimages.com/asr/a6f53c0f-31d5...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$99.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  High-Efficiency HEPA-Type Desktop Air Purifier...   \n",
       "1  Filtrete F2 Bacteria & Virus True HEPA Room Ai...   \n",
       "2  Filtrete by 3M Room Air Purifier, Console, 110...   \n",
       "3  Air Purifier for Home Large Room with HEPA Fil...   \n",
       "4  Airfree T800 Filterless Virus Destroying Air P...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.walmart.com/ip/High-Efficiency-HEP...   \n",
       "1  https://www.walmart.com/ip/Filtrete-F2-Bacteri...   \n",
       "2  https://www.walmart.com/ip/Filtrete-by-3M-Room...   \n",
       "3  https://www.walmart.com/ip/Air-Purifier-Home-L...   \n",
       "4  https://www.walmart.com/ip/Airfree-T800-Filter...   \n",
       "\n",
       "                                               Image AverageStars  \\\n",
       "0  https://i5.walmartimages.com/asr/5ba9740e-a3f1...          4.4   \n",
       "1  https://i5.walmartimages.com/asr/dea94bac-be28...          4.8   \n",
       "2  https://i5.walmartimages.com/asr/eae28c2f-5dbe...          4.6   \n",
       "3  https://i5.walmartimages.com/asr/ea3ecf29-543f...          3.3   \n",
       "4  https://i5.walmartimages.com/asr/a6f53c0f-31d5...            0   \n",
       "\n",
       "  NumberofReviews                                         ReviewsURL   Price  \n",
       "0             136  https://www.walmart.com/ip/High-Efficiency-HEP...  $52.30  \n",
       "1              55  https://www.walmart.com/ip/Filtrete-F2-Bacteri...  $17.97  \n",
       "2             195  https://www.walmart.com/ip/Filtrete-by-3M-Room...  $49.94  \n",
       "3               3  https://www.walmart.com/ip/Air-Purifier-Home-L...  $88.88  \n",
       "4               0                                                NaN  $99.00  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty lists for scraped data to be stored in.\n",
    "productURL_list = []\n",
    "productImage_list = []\n",
    "productTitle_list = []\n",
    "starReview_list = []\n",
    "reviewAmount_list = []\n",
    "currentPrice_list = []\n",
    "reviewURL_list = []\n",
    "\n",
    "\n",
    "listOfPages = soup.find('ul', class_='paginator-list').find_all('li')\n",
    "# print(listOfPages)\n",
    "numberOfPages = listOfPages[0].find('a')['aria-label'].split()[3]\n",
    "print(numberOfPages)\n",
    "\n",
    "for i in numberOfPages:\n",
    "\n",
    "    today = datetime.datetime.now()\n",
    "\n",
    "    for product in products:\n",
    "\n",
    "        # Get the link to the product page.\n",
    "        link = product.find('a')\n",
    "        href = link['href']\n",
    "        product_url = base_url + href\n",
    "        productURL_list.append(product_url)\n",
    "\n",
    "        # Get the link to the product image.\n",
    "        img = product.find('img')['src']\n",
    "        productImage_list.append(img)\n",
    "\n",
    "        # Get the product title.\n",
    "        product_title = product.find('img')['alt']\n",
    "        productTitle_list.append(product_title)\n",
    "\n",
    "        # Try to get the number of reviews, there may not be any.\n",
    "        try:\n",
    "            review_amount = product.find('span', class_='seo-review-count visuallyhidden').text\n",
    "            reviewAmount_list.append(review_amount)\n",
    "\n",
    "        except:\n",
    "            review_amount = 0\n",
    "            reviewAmount_list.append(review_amount)\n",
    "\n",
    "        # In the case where there are at least one review...\n",
    "        if int(review_amount) > 0:\n",
    "            # Get the average number of stars\n",
    "            stars_review = product.find('span', class_='visuallyhidden seo-avg-rating').text   \n",
    "            starReview_list.append(stars_review)\n",
    "\n",
    "            # Get the URL to the reviews section for that product.\n",
    "            review_url = product.find('div', class_='stars').find('a')['href']\n",
    "            reviewURL_list.append(base_url+review_url)\n",
    "\n",
    "        # Otherwise, use defalt 0 or NaN values for these entries.\n",
    "        else:\n",
    "            stars_review = 0\n",
    "            starReview_list.append(stars_review)\n",
    "\n",
    "            review_url = \"NaN\"\n",
    "            reviewURL_list.append(review_url)\n",
    "\n",
    "        # Get the price of the product.\n",
    "        price = product.find('span', class_='price-main')\n",
    "        current_price = price.find('span', class_='visuallyhidden').text\n",
    "        currentPrice_list.append(current_price)\n",
    "\n",
    "    # Close the browser window\n",
    "    # browser.quit()\n",
    "\n",
    "    # Create a dictionary with the lists of the scrapped data.\n",
    "    data = {\n",
    "        \"Title\": productTitle_list,\n",
    "        \"URL\": productURL_list,\n",
    "        \"Image\": productImage_list,\n",
    "        \"AverageStars\": starReview_list,\n",
    "        \"NumberofReviews\": reviewAmount_list,\n",
    "        \"ReviewsURL\": reviewURL_list,\n",
    "        \"Price\": currentPrice_list\n",
    "           }\n",
    "\n",
    "    # Create a Pandas DataFrame with that dictionary\n",
    "    product_df = pd.DataFrame.from_dict(data)\n",
    "    product_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title               object\n",
       "URL                 object\n",
       "Image               object\n",
       "AverageStars       float64\n",
       "NumberofReviews      int64\n",
       "ReviewsURL          object\n",
       "Price               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df = product_df.astype({\n",
    "    \"NumberofReviews\": 'int',\n",
    "    \"AverageStars\": 'float'\n",
    "})\n",
    "\n",
    "product_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageStars</th>\n",
       "      <th>NumberofReviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.582500</td>\n",
       "      <td>85.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.734401</td>\n",
       "      <td>149.415474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.825000</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>103.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>712.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AverageStars  NumberofReviews\n",
       "count     40.000000        40.000000\n",
       "mean       3.582500        85.125000\n",
       "std        1.734401       149.415474\n",
       "min        0.000000         0.000000\n",
       "25%        3.825000         2.750000\n",
       "50%        4.400000        19.000000\n",
       "75%        4.500000       103.500000\n",
       "max        5.000000       712.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# nextbutton = soup.find('button', class_='paginator-btn')\n",
    "# nextbutton = browser.find_by_name('2').first.click()\n",
    "# browser.visit(nextbutton)\n",
    "listOfPages = soup.find('ul', class_='paginator-list').find_all('li')\n",
    "# print(listOfPages)\n",
    "numberOfPages = listOfPages[0].find('a')['aria-label'].split()[3]\n",
    "print(numberOfPages)\n",
    "# page 1 &amp;cat_id=0&amp;grid=true&amp;ps=40\n",
    "# page 2 &amp;page=2&amp;cat_id=0&amp;grid=true&amp;ps=40\n",
    "# page 3 &amp;page=3&amp;cat_id=0&amp;grid=true&amp;ps=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add to existing dataframe\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'productReviews_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9cfb5f85977a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'add to existing dataframe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mreview_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproductReviews_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m#                 browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'productReviews_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Get reviews \n",
    "\n",
    "review_df = pd.DataFrame()\n",
    "\n",
    "# for i in range(len(product_df[\"ReviewsURL\"])):\n",
    "for i in range(4,6):\n",
    "    if product_df['NumberofReviews'][i] > 0:\n",
    "        \n",
    "        productTitleList = []\n",
    "        reviewURLList = []\n",
    "        reviewTitleList = []\n",
    "        reviewRatingList = []\n",
    "        reviewCommentList = []\n",
    "        \n",
    "        if len(reviewRatingList) < product_df['NumberofReviews'][i]:\n",
    "#         while len(reviewRatingList) < product_df['NumberofReviews'][i]:\n",
    "    \n",
    "            try:\n",
    "                browser.visit(product_df[\"ReviewsURL\"][i])\n",
    "                html = browser.html\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                allReviewsURL = soup.find('a', class_=\"button ReviewBtn-container ReviewsHeader-seeAll button--primary\")['href']\n",
    "                browser.visit(base_url+allReviewsURL)\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                reviews = soup.find_all('div', class_='ReviewList-content')\n",
    "\n",
    "                # need to add a way to make sure I am capturing all of the reviews\n",
    "                # can check this by looking at NumberofReview for this ReviewsRUL\n",
    "                # to scroll down a little use the below command\n",
    "                # browser.execute_script(\"window.scrollTo(200, document.body.scrollHeight);\")\n",
    "                # check the average rating by using the values found here\n",
    "\n",
    "\n",
    "\n",
    "                for review in reviews:\n",
    "\n",
    "                    productTitleList.append(product_df['Title'][i])\n",
    "                    reviewURLList.append(product_df['ReviewsURL'][i])\n",
    "\n",
    "                    try:\n",
    "                        title = review.find('h3', class_='review-title').text\n",
    "                        reviewTitleList.append(title)\n",
    "                        print(title)\n",
    "\n",
    "                    except:\n",
    "                        title = 'None'\n",
    "                        reviewTitleList.append(title)\n",
    "                        print(title)\n",
    "#                         pass\n",
    "\n",
    "                    # adding try only because the browser needs to scroll\n",
    "                    # once this is added, there wont need to be a try\n",
    "                    # each review has to have a star value\n",
    "                    try:\n",
    "                        reviewRating = review.find('span', class_='seo-avg-rating').text\n",
    "                        reviewRatingList.append(reviewRating)\n",
    "                        print(reviewRating)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    # adding try and except for the review body for same reason as stars\n",
    "                    try:\n",
    "                        reviewComment = review.find('p').text\n",
    "                        reviewCommentList.append(reviewComment)\n",
    "#                         print(reviewComment)\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "            \n",
    "                # only until I fix the scroll\n",
    "                reviewTitleList.pop()\n",
    "                productTitleList.pop()\n",
    "                reviewURLList.pop()\n",
    "                \n",
    "                data = {\n",
    "                    'ProductTitle': productTitleList,\n",
    "                    'ReviewURL': reviewURLList,\n",
    "                    'ReviewTitle': reviewTitleList,\n",
    "                    'ReviewStarRating': reviewRatingList,\n",
    "                    'ReviewComment': reviewCommentList\n",
    "                }\n",
    "                print('stored data')\n",
    "                productReviews_df = pd.DataFrame.from_dict(data)\n",
    "                productReviews_df.head()\n",
    "                print('into dataframe')\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        print('add to existing dataframe')\n",
    "        review_df = review_df.append(productReviews_df, ignore_index=True)\n",
    "print('done')\n",
    "#                 browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(review_df)\n",
    "# review_df.tail()\n",
    "review_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = soup.find('div', class_='review-highlight')\n",
    "positive = reviews.find('div', class_='font-bold highlight-title').text\n",
    "stars = reviews.find('span', class_='seo-avg-rating').text\n",
    "# starts = reviews.find('span', class_='seo-average-rating')\n",
    "body = reviews.find('div', class_='collapsable-content-container').text\n",
    "print(positive)\n",
    "print(stars)\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = soup.find_all('div', class_='ReviewList-content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add to existing dataframe\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'productReviews_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d5319701dff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'add to existing dataframe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mreview_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproductReviews_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'productReviews_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Get reviews \n",
    "\n",
    "review_df = pd.DataFrame()\n",
    "\n",
    "# for i in range(len(product_df[\"ReviewsURL\"])):\n",
    "for i in range(4,5):\n",
    "    if product_df['NumberofReviews'][i] > 0:\n",
    "#     number_of_reviews = product_df['NumberofReviews'][i]\n",
    "#     for j in range(number_of_reviews):\n",
    "        \n",
    "        productTitleList = []\n",
    "        reviewURLList = []\n",
    "        reviewSiteLink = []\n",
    "        reviewTitleList = []\n",
    "        reviewRatingList = []\n",
    "        reviewCommentList = []\n",
    "        \n",
    "#         if len(reviewRatingList) < product_df['NumberofReviews'][i]:\n",
    "        \n",
    "#         while len(reviewRatingList) < product_df['NumberofReviews'][i]:\n",
    "    \n",
    "        try:\n",
    "            # go to the product url link\n",
    "            browser.visit(product_df[\"ReviewsURL\"][i])\n",
    "            html = browser.html\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "            # find the 'see all reviews' button and go there\n",
    "            allReviewsURL = soup.find('a', class_=\"button ReviewBtn-container ReviewsHeader-seeAll button--primary\")['href']\n",
    "            browser.visit(base_url+allReviewsURL)\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "            # find the list of reviews\n",
    "            reviews = soup.find_all('div', class_='ReviewList-content')\n",
    "            \n",
    "#             for review in reviews:\n",
    "            for j in range(len(reviews)):\n",
    "                reviewSiteLink.append(review)\n",
    "                reviewSiteLink[j].send_keys(Keys.PAGE_DOWN)\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                reviews = soup.find('div', class_='ReviewList-content')\n",
    "                \n",
    "#                 print(f\"j={j}\")\n",
    "                productTitleList.append(product_df['Title'][i])\n",
    "                reviewURLList.append(product_df['ReviewsURL'][i])\n",
    "                title, stars, comments = scrapeReviews(review)\n",
    "                reviewTitleList.append(title)\n",
    "                reviewRatingList.append(stars)\n",
    "                reviewCommentList.append(comments)\n",
    "\n",
    "\n",
    "                data = {\n",
    "                    'ProductTitle': productTitleList,\n",
    "                    'ReviewURL': reviewURLList,\n",
    "                    'ReviewTitle': reviewTitleList,\n",
    "                    'ReviewStarRating': reviewRatingList,\n",
    "                    'ReviewComment': reviewCommentList\n",
    "                }\n",
    "                print('stored data')\n",
    "                productReviews_df = pd.DataFrame.from_dict(data)\n",
    "                productReviews_df.head()\n",
    "                print('into dataframe')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print('add to existing dataframe')\n",
    "        review_df = review_df.append(productReviews_df, ignore_index=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(review_df)\n",
    "# review_df.tail()\n",
    "review_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeReviews(review):\n",
    "    \n",
    "    # get the title of the review\n",
    "    try:\n",
    "        title = review.find('h3', class_='review-title').text\n",
    "    except:\n",
    "        title = 'None'\n",
    "        \n",
    "    # get the number of stars in this review\n",
    "    reviewRating = review.find('span', class_='seo-avg-rating').text\n",
    "    \n",
    "    # get the context of the review\n",
    "    reviewComment = review.find('p').text\n",
    "        \n",
    "    # return these items as a tuple\n",
    "    return title, stars, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
