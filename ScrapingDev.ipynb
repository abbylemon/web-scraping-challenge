{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed to run this app\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import time, datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depreciated way of opening ChromeDriver\n",
    "\n",
    "# !which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 84.0.4147\n",
      "[WDM] - Get LATEST driver version for 84.0.4147\n",
      "[WDM] - Get LATEST driver version for 84.0.4147\n",
      "[WDM] - Trying to download new driver from http://chromedriver.storage.googleapis.com/84.0.4147.30/chromedriver_mac64.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver has been saved in cache [/Users/abby/.wdm/drivers/chromedriver/mac64/84.0.4147.30]\n"
     ]
    }
   ],
   "source": [
    "# open ChromeDriver\n",
    "\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to the disired url\n",
    "\n",
    "base_url = 'https://www.walmart.com'\n",
    "search_url = '/search/?query=room%20air%20purifier'\n",
    "browser.visit(base_url + search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the html and parse it\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of pages to loop through is 11\n",
      "quering page 1...............\n",
      "quering page 2...............\n",
      "quering page 3...............\n",
      "quering page 4...............\n",
      "quering page 5...............\n",
      "quering page 6...............\n",
      "quering page 7...............\n",
      "quering page 8...............\n",
      "quering page 9...............\n",
      "quering page 10...............\n",
      "quering page 11...............\n"
     ]
    }
   ],
   "source": [
    "# Do the product scrape\n",
    "\n",
    "# Create empty lists for scraped data to be stored in.\n",
    "productURL_list = []\n",
    "productImage_list = []\n",
    "productTitle_list = []\n",
    "starReview_list = []\n",
    "reviewAmount_list = []\n",
    "currentPrice_list = []\n",
    "reviewURL_list = []\n",
    "freepickup_list = []\n",
    "\n",
    "# Find the number of pages for this site\n",
    "listOfPages = soup.find('ul', class_='paginator-list').find_all('li')\n",
    "numberOfPages = listOfPages[0].find('a')['aria-label'].split()[3]\n",
    "print(f\"the number of pages to loop through is {numberOfPages}\")\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "for i in range(1,int(numberOfPages)+1):\n",
    "# for i in range(1,2):\n",
    "    \n",
    "    # click on the next page number and scrape the html\n",
    "\n",
    "    \n",
    "    # loop through all of the products on that page\n",
    "    products = soup.find_all('div', class_='search-result-gridview-item')\n",
    "    print(f\"quering page {i}...............\")\n",
    "\n",
    "    for product in products:\n",
    "\n",
    "# Get the link to the product page.\n",
    "        link = product.find('a')\n",
    "        href = link['href']\n",
    "        product_url = base_url + href\n",
    "        productURL_list.append(product_url)\n",
    "\n",
    "# Get the link to the product image.\n",
    "        img = product.find('img')['src']\n",
    "        productImage_list.append(img)\n",
    "\n",
    "# Get the product title.\n",
    "        product_title = product.find('img')['alt']\n",
    "        productTitle_list.append(product_title)\n",
    "\n",
    "# Get the number of reviews, there may not be any.\n",
    "        try:\n",
    "            review_amount = product.find('span', class_='seo-review-count visuallyhidden').text\n",
    "            reviewAmount_list.append(review_amount)\n",
    "\n",
    "        except:\n",
    "            review_amount = 0\n",
    "            reviewAmount_list.append(review_amount)\n",
    "\n",
    "        # In the case where there are at least one review...\n",
    "        if int(review_amount) > 0:\n",
    "            # Get the average number of stars\n",
    "            stars_review = product.find('span', class_='visuallyhidden seo-avg-rating').text   \n",
    "            starReview_list.append(stars_review)\n",
    "\n",
    "            # Get the URL to the reviews section for that product.\n",
    "            review_url = product.find('div', class_='stars').find('a')['href']\n",
    "            reviewURL_list.append(base_url+review_url)\n",
    "\n",
    "        # Otherwise, use defalt 0 or NaN values for these entries.\n",
    "        else:\n",
    "            stars_review = 0\n",
    "            starReview_list.append(stars_review)\n",
    "\n",
    "            review_url = \"NaN\"\n",
    "            reviewURL_list.append(review_url)\n",
    "\n",
    "# Get the price of the product.\n",
    "        try:\n",
    "            price = product.find('span', class_='price-main-block')\n",
    "            current_price = price.find('span', class_='visuallyhidden').text\n",
    "        # Some products don't have a specific price, or price is only shown in cart\n",
    "        except:\n",
    "            price = product.find('span', class_='search-result-productprice')\n",
    "            current_price = price.find('span', class_='visuallyhidden').text\n",
    "        \n",
    "        currentPrice_list.append(current_price)\n",
    "        \n",
    "# Check to see if the product has 'Free pickup' AKA in store\n",
    "        # Look at the div under the price div\n",
    "        try:\n",
    "            shipping_details = product.find('div', class_='search-result-product-shipping-details')\n",
    "            delivery_options_list = []\n",
    "            # loop through all possile delivery options displayed\n",
    "            for option in shipping_details.children:\n",
    "                option.span.unwrap() #unwrap takes the span tag off\n",
    "                delivery_option = option.text\n",
    "                if delivery_option == 'Free pickup': #assuming 'free pickup' means avaliable in store\n",
    "                    free_pickup = True\n",
    "                    delivery_options_list.append(free_pickup)\n",
    "                else:\n",
    "                    free_pickup = False\n",
    "                    delivery_options_list.append(free_pickup)\n",
    "\n",
    "            instore = any(delivery_options_list)\n",
    "        # if there are no delivery options, assume not avaialble in store\n",
    "        except:\n",
    "            instore = False\n",
    "        freepickup_list.append(instore)\n",
    "\n",
    "    # Close the browser window\n",
    "    # browser.quit()\n",
    "\n",
    "    # Create a dictionary with the lists of the scrapped data.\n",
    "    data = {\n",
    "        \"Title\": productTitle_list,\n",
    "        \"URL\": productURL_list,\n",
    "        \"Image\": productImage_list,\n",
    "        \"AverageStars\": starReview_list,\n",
    "        \"NumberofReviews\": reviewAmount_list,\n",
    "        \"ReviewsURL\": reviewURL_list,\n",
    "        \"Price\": currentPrice_list,\n",
    "        \"Free Pickup\": freepickup_list\n",
    "           }\n",
    "\n",
    "    # Create a Pandas DataFrame with that dictionary\n",
    "    product_df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title               object\n",
       "URL                 object\n",
       "Image               object\n",
       "AverageStars       float64\n",
       "NumberofReviews      int64\n",
       "ReviewsURL          object\n",
       "Price               object\n",
       "Free Pickup           bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# casting columns as necessary and checking the data types\n",
    "\n",
    "product_df = product_df.astype({\n",
    "    \"NumberofReviews\": 'int',\n",
    "    \"AverageStars\": 'float'\n",
    "})\n",
    "\n",
    "product_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Image</th>\n",
       "      <th>AverageStars</th>\n",
       "      <th>NumberofReviews</th>\n",
       "      <th>ReviewsURL</th>\n",
       "      <th>Price</th>\n",
       "      <th>Free Pickup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Envion Ionic Pro CA 200 Compact Air Purifier M...</td>\n",
       "      <td>https://www.walmart.com/ip/Envion-Ionic-Pro-CA...</td>\n",
       "      <td>https://i5.walmartimages.com/asr/0715b6c6-03e5...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>380</td>\n",
       "      <td>https://www.walmart.com/ip/Envion-Ionic-Pro-CA...</td>\n",
       "      <td>$79.94</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Envion Ionic Pro CA 200 Compact Air Purifier M...</td>\n",
       "      <td>https://www.walmart.com/ip/Envion-Ionic-Pro-CA...</td>\n",
       "      <td>https://i5.walmartimages.com/asr/0715b6c6-03e5...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>380</td>\n",
       "      <td>https://www.walmart.com/ip/Envion-Ionic-Pro-CA...</td>\n",
       "      <td>$79.94</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Honeywell HEPA Allergen Remover Air Purifier, ...</td>\n",
       "      <td>https://www.walmart.com/ip/Honeywell-HEPA-Alle...</td>\n",
       "      <td>https://i5.walmartimages.com/asr/3574cc6b-93c9...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>261</td>\n",
       "      <td>https://www.walmart.com/ip/Honeywell-HEPA-Alle...</td>\n",
       "      <td>$220.99</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Honeywell HEPA Allergen Remover Air Purifier, ...</td>\n",
       "      <td>https://www.walmart.com/ip/Honeywell-HEPA-Alle...</td>\n",
       "      <td>https://i5.walmartimages.com/asr/3574cc6b-93c9...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>261</td>\n",
       "      <td>https://www.walmart.com/ip/Honeywell-HEPA-Alle...</td>\n",
       "      <td>$220.99</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Honeywell QuietCare True HEPA Air Purifier 170...</td>\n",
       "      <td>https://www.walmart.com/ip/Honeywell-QuietCare...</td>\n",
       "      <td>https://i5.walmartimages.com/asr/9b9d31d5-1e81...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>166</td>\n",
       "      <td>https://www.walmart.com/ip/Honeywell-QuietCare...</td>\n",
       "      <td>$147.01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "9    Envion Ionic Pro CA 200 Compact Air Purifier M...   \n",
       "49   Envion Ionic Pro CA 200 Compact Air Purifier M...   \n",
       "7    Honeywell HEPA Allergen Remover Air Purifier, ...   \n",
       "47   Honeywell HEPA Allergen Remover Air Purifier, ...   \n",
       "123  Honeywell QuietCare True HEPA Air Purifier 170...   \n",
       "\n",
       "                                                   URL  \\\n",
       "9    https://www.walmart.com/ip/Envion-Ionic-Pro-CA...   \n",
       "49   https://www.walmart.com/ip/Envion-Ionic-Pro-CA...   \n",
       "7    https://www.walmart.com/ip/Honeywell-HEPA-Alle...   \n",
       "47   https://www.walmart.com/ip/Honeywell-HEPA-Alle...   \n",
       "123  https://www.walmart.com/ip/Honeywell-QuietCare...   \n",
       "\n",
       "                                                 Image  AverageStars  \\\n",
       "9    https://i5.walmartimages.com/asr/0715b6c6-03e5...           4.0   \n",
       "49   https://i5.walmartimages.com/asr/0715b6c6-03e5...           4.0   \n",
       "7    https://i5.walmartimages.com/asr/3574cc6b-93c9...           4.6   \n",
       "47   https://i5.walmartimages.com/asr/3574cc6b-93c9...           4.6   \n",
       "123  https://i5.walmartimages.com/asr/9b9d31d5-1e81...           4.5   \n",
       "\n",
       "     NumberofReviews                                         ReviewsURL  \\\n",
       "9                380  https://www.walmart.com/ip/Envion-Ionic-Pro-CA...   \n",
       "49               380  https://www.walmart.com/ip/Envion-Ionic-Pro-CA...   \n",
       "7                261  https://www.walmart.com/ip/Honeywell-HEPA-Alle...   \n",
       "47               261  https://www.walmart.com/ip/Honeywell-HEPA-Alle...   \n",
       "123              166  https://www.walmart.com/ip/Honeywell-QuietCare...   \n",
       "\n",
       "       Price  Free Pickup  \n",
       "9     $79.94         True  \n",
       "49    $79.94         True  \n",
       "7    $220.99         True  \n",
       "47   $220.99         True  \n",
       "123  $147.01         True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordering dataframe before saving as csv\n",
    "\n",
    "ordered_df = product_df.sort_values(by=['Free Pickup', 'NumberofReviews'], ascending=False)\n",
    "ordered_df.head()\n",
    "# shortlist_df = product_df.sort_values(by='NumberofReviews', ascending=False)[product_df['Free Pickup']==True]\n",
    "# shortlist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageStars</th>\n",
       "      <th>NumberofReviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>434.000000</td>\n",
       "      <td>434.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.127118</td>\n",
       "      <td>28.460829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.217700</td>\n",
       "      <td>76.656244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>548.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AverageStars  NumberofReviews\n",
       "count    434.000000       434.000000\n",
       "mean       2.127118        28.460829\n",
       "std        2.217700        76.656244\n",
       "min        0.000000         0.000000\n",
       "25%        0.000000         0.000000\n",
       "50%        1.000000         1.000000\n",
       "75%        4.500000        11.000000\n",
       "max        5.000000       548.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the length of the dataframe and other stats\n",
    "\n",
    "# product_df.describe()\n",
    "# product_df.head(6)\n",
    "ordered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv with datetime of scrape\n",
    "# dd/mm/YY H:M:S\n",
    "\n",
    "dt_string = now.strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
    "ordered_df.to_csv(f\"WalmartRAPScrape_{dt_string}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Scrape Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Testing Comments Scrape Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.walmart.com/ip/Airfree-Air-Purifier-Sancusto-3-in-1-Cleaner-Purifier-True-HEPA-Filter-Mosquito-Repellent-Tower-Fan-Capture-Allergens-Timer-Function-Home-Room-Office/197063613?wpa_bd=&wpa_pg_seller_id=22063D98FBBD4EAE9E93364F0597F233&wpa_ref_id=wpaqs:4TXzo0s2yJdNA-6ymy-QKY-zq-1x1sEuqL6cyhYkVxtfTlLv4Zgpz_XuskG3GjuVE7dZcl5yiIR5kY_XgDTWHR0yIHvsh0PmD-93Hn6RqyxsSnG4MK_sDSdgNSk-fQ-YS3KJ99kuOoWiPmv0bPOmqd6y9nRTbCvZnGlg2xn4EhSdU3WzxNQdQamT6ya2xcfLzvutgEcxFvKSYet36H1sSQ&wpa_tag=&wpa_aux_info=&wpa_pos=1&wpa_plmt=1145x1145_T-C-IG_TI_1-2_HL-INGRID-GRID-NY&wpa_aduid=cced3464-9b29-4873-b4bc-4bcac51f8564&wpa_pg=search&wpa_pg_id=room air purifier&wpa_st=room%2Bair%2Bpurifier&wpa_tax=1072864_133032_1231459_46324_2001565&wpa_bucket=__bkt__\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://www.walmart.com/ip/Holmes-TRUE-HEPA-Console-Air-Purifier-with-Filter-Life-nbsp-Monitor-Bar-and-Quiet-Operation-Large-Room-Air-Cleaner-Black-HAP8650B-NU-2/22351038#customer-reviews\n"
     ]
    }
   ],
   "source": [
    "print(product_df['URL'][0])\n",
    "print('----------------------------------------------------------------------------------------------------')\n",
    "print(product_df['ReviewsURL'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of pages to loop through is 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c49900dec6f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"the number of pages to loop through is {pagesOfReviews}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpagesOfReviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mpage_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviewPages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#             print(page_link)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# LEFT OFF HERE\n",
    "# WANT TO CLICK BY TEXT LIKE IN ABOVE QUERY, DIDN'T WORK THOUGH...\n",
    "# THIS WILL LET ME GO TO EACH PAGE OF THE REVIEWS, \n",
    "# AND I THINK IT WILL LET ME LOAD ALL OF THAT PAGES REVIEWS\n",
    "\n",
    "# Get reviews \n",
    "\n",
    "review_df = pd.DataFrame()\n",
    "\n",
    "# loop through all of the products in the product dataframe\n",
    "# for i in range(len(product_df[\"ReviewsURL\"])):\n",
    "for i in range(4,6):\n",
    "    if product_df['NumberofReviews'][i] > 0:\n",
    "        \n",
    "        productTitleList = []\n",
    "        reviewURLList = []\n",
    "        reviewTitleList = []\n",
    "        reviewRatingList = []\n",
    "        reviewCommentList = []\n",
    "    \n",
    "#         try:\n",
    "        browser.visit(product_df[\"ReviewsURL\"][i])\n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        allReviewsURL = soup.find('a', class_=\"button ReviewBtn-container ReviewsHeader-seeAll button--primary\")['href']\n",
    "        browser.visit(base_url+allReviewsURL)\n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # loop through all of the pages in this search\n",
    "        reviewPages = soup.find('ul', class_='paginator-list').find_all('li')\n",
    "        pagesOfReviews = reviewPages[-1].find('button').text\n",
    "        print(f\"the number of pages to loop through is {pagesOfReviews}\")\n",
    "        for j in range(int(pagesOfReviews)):\n",
    "            page_link = reviewPages[j].click()\n",
    "            \n",
    "#             print(page_link)\n",
    "\n",
    "#             page_link = soup.links.find_by_text(j).click()\n",
    "#             html = browser.html\n",
    "#             soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "\n",
    "#             reviews = soup.find_all('div', class_='Grid ReviewList-content')\n",
    "#             print(len(reviews))\n",
    "#             for review in reviews:\n",
    "\n",
    "#                 productTitleList.append(product_df['Title'][i])\n",
    "#                 reviewURLList.append(product_df['ReviewsURL'][i])\n",
    "\n",
    "#                 try:\n",
    "#                     title = review.find('h3', class_='review-title').text\n",
    "#                     reviewTitleList.append(title)\n",
    "#                     print(title)\n",
    "\n",
    "#                 except:\n",
    "#                     title = 'None'\n",
    "#                     reviewTitleList.append(title)\n",
    "#                     print(title)\n",
    "#                         pass\n",
    "\n",
    "#                 # adding try only because the browser needs to scroll\n",
    "#                 # once this is added, there wont need to be a try\n",
    "#                 # each review has to have a star value\n",
    "#                 try:\n",
    "#                     reviewRating = review.find('span', class_='seo-avg-rating').text\n",
    "#                     reviewRatingList.append(reviewRating)\n",
    "#                     print(reviewRating)\n",
    "#                 except:\n",
    "#                     pass\n",
    "\n",
    "#                 # adding try and except for the review body for same reason as stars\n",
    "#                 try:\n",
    "#                     reviewComment = review.find('p').text\n",
    "#                     reviewCommentList.append(reviewComment)\n",
    "# #                         print(reviewComment)\n",
    "#                 except:\n",
    "#                     pass\n",
    "\n",
    "\n",
    "#             # only until I fix the scroll\n",
    "#             reviewTitleList.pop()\n",
    "#             productTitleList.pop()\n",
    "#             reviewURLList.pop()\n",
    "\n",
    "#             data = {\n",
    "#                 'ProductTitle': productTitleList,\n",
    "#                 'ReviewURL': reviewURLList,\n",
    "#                 'ReviewTitle': reviewTitleList,\n",
    "#                 'ReviewStarRating': reviewRatingList,\n",
    "#                 'ReviewComment': reviewCommentList\n",
    "#             }\n",
    "#             print('stored data')\n",
    "#             productReviews_df = pd.DataFrame.from_dict(data)\n",
    "#             productReviews_df.head()\n",
    "#             print('into dataframe')\n",
    "\n",
    "#         except:\n",
    "#             pass\n",
    "    \n",
    "#         print('add to existing dataframe')\n",
    "#         review_df = review_df.append(productReviews_df, ignore_index=True)\n",
    "# print('done')\n",
    "# #                 browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(review_df)\n",
    "# review_df.tail()\n",
    "review_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = soup.find('div', class_='review-highlight')\n",
    "positive = reviews.find('div', class_='font-bold highlight-title').text\n",
    "stars = reviews.find('span', class_='seo-avg-rating').text\n",
    "# starts = reviews.find('span', class_='seo-average-rating')\n",
    "body = reviews.find('div', class_='collapsable-content-container').text\n",
    "print(positive)\n",
    "print(stars)\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = soup.find_all('div', class_='ReviewList-content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reviews \n",
    "\n",
    "review_df = pd.DataFrame()\n",
    "\n",
    "# for i in range(len(product_df[\"ReviewsURL\"])):\n",
    "for i in range(4,5):\n",
    "    if product_df['NumberofReviews'][i] > 0:\n",
    "#     number_of_reviews = product_df['NumberofReviews'][i]\n",
    "#     for j in range(number_of_reviews):\n",
    "        \n",
    "        productTitleList = []\n",
    "        reviewURLList = []\n",
    "        reviewSiteLink = []\n",
    "        reviewTitleList = []\n",
    "        reviewRatingList = []\n",
    "        reviewCommentList = []\n",
    "        \n",
    "#         if len(reviewRatingList) < product_df['NumberofReviews'][i]:\n",
    "        \n",
    "#         while len(reviewRatingList) < product_df['NumberofReviews'][i]:\n",
    "    \n",
    "        try:\n",
    "            # go to the product url link\n",
    "            browser.visit(product_df[\"ReviewsURL\"][i])\n",
    "            html = browser.html\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "            # find the 'see all reviews' button and go there\n",
    "            allReviewsURL = soup.find('a', class_=\"button ReviewBtn-container ReviewsHeader-seeAll button--primary\")['href']\n",
    "            browser.visit(base_url+allReviewsURL)\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "            # find the list of reviews\n",
    "            reviews = soup.find_all('div', class_='ReviewList-content')\n",
    "            \n",
    "#             for review in reviews:\n",
    "            for j in range(len(reviews)):\n",
    "                reviewSiteLink.append(review)\n",
    "                reviewSiteLink[j].send_keys(Keys.PAGE_DOWN)\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                reviews = soup.find('div', class_='ReviewList-content')\n",
    "                \n",
    "#                 print(f\"j={j}\")\n",
    "                productTitleList.append(product_df['Title'][i])\n",
    "                reviewURLList.append(product_df['ReviewsURL'][i])\n",
    "                title, stars, comments = scrapeReviews(review)\n",
    "                reviewTitleList.append(title)\n",
    "                reviewRatingList.append(stars)\n",
    "                reviewCommentList.append(comments)\n",
    "\n",
    "\n",
    "                data = {\n",
    "                    'ProductTitle': productTitleList,\n",
    "                    'ReviewURL': reviewURLList,\n",
    "                    'ReviewTitle': reviewTitleList,\n",
    "                    'ReviewStarRating': reviewRatingList,\n",
    "                    'ReviewComment': reviewCommentList\n",
    "                }\n",
    "                print('stored data')\n",
    "                productReviews_df = pd.DataFrame.from_dict(data)\n",
    "                productReviews_df.head()\n",
    "                print('into dataframe')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print('add to existing dataframe')\n",
    "        review_df = review_df.append(productReviews_df, ignore_index=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(review_df)\n",
    "# review_df.tail()\n",
    "review_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeReviews(review):\n",
    "    \n",
    "    # get the title of the review\n",
    "    try:\n",
    "        title = review.find('h3', class_='review-title').text\n",
    "    except:\n",
    "        title = 'None'\n",
    "        \n",
    "    # get the number of stars in this review\n",
    "    reviewRating = review.find('span', class_='seo-avg-rating').text\n",
    "    \n",
    "    # get the context of the review\n",
    "    reviewComment = review.find('p').text\n",
    "        \n",
    "    # return these items as a tuple\n",
    "    return title, stars, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
